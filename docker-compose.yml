version: '3.8'

services:
  # Elasticsearch for log storage and search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.16.2
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=${ES_CLUSTER_NAME:-securiwatch-cluster}
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms${ES_HEAP_SIZE:-1g} -Xmx${ES_HEAP_SIZE:-1g}"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      # Use bind mount to store data locally within ./data
      - ./data/elasticsearch:/usr/share/elasticsearch/data
    networks:
      - securiwatch-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '${ES_CPU_LIMIT:-2}'
          memory: ${ES_MEM_LIMIT:-2g}
        reservations:
          cpus: '0.5'
          memory: 1g
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:9200"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Kibana for visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:7.16.2
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    volumes:
      - ./config/kibana:/usr/share/kibana/config/dashboards
    networks:
      - securiwatch-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '${KI_CPU_LIMIT:-1}'
          memory: ${KI_MEM_LIMIT:-1g}
        reservations:
          cpus: '0.25'
          memory: 512m
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:5601/app/kibana"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Logstash for log processing
  logstash:
    image: docker.elastic.co/logstash/logstash:7.16.2
    container_name: logstash
    environment:
      - "LS_JAVA_OPTS=-Xms${LS_HEAP_SIZE:-512m} -Xmx${LS_HEAP_SIZE:-512m}"
    volumes:
      - ./config/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./config/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
    ports:
      - "5044:5044"      # Beats input
      - "5140:5140/udp"  # Syslog input
      - "5000:5000"      # TCP input (e.g., JSON over TCP)
    networks:
      - securiwatch-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '${LS_CPU_LIMIT:-1}'
          memory: ${LS_MEM_LIMIT:-1g}
        reservations:
          cpus: '0.25'
          memory: 512m
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:9600"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Wazuh manager for security monitoring
  wazuh-manager:
    image: wazuh/wazuh-manager:4.3.8
    container_name: wazuh-manager
    ports:
      - "1514:1514/udp" # Agent Syslog
      - "1515:1515"     # Agent Enrollment
      - "55000:55000"   # Wazuh API
    volumes:
      # Use bind mounts
      - ./data/wazuh-manager-config:/var/ossec/etc
      - ./data/wazuh-manager-data:/var/ossec/data
    networks:
      - securiwatch-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '${WZ_MGR_CPU_LIMIT:-1.5}'
          memory: ${WZ_MGR_MEM_LIMIT:-1.5g}
        reservations:
          cpus: '0.5'
          memory: 1g
    # Wazuh manager image does not have a built-in healthcheck command easily usable

  # Wazuh dashboard for monitoring
  wazuh-dashboard:
    image: wazuh/wazuh-dashboard:4.3.8
    container_name: wazuh-dashboard
    environment:
      # Needs direct HTTPS comms with ES; requires trusting ES cert or disabling verification
      # For simplicity with self-signed certs, often verification is disabled internally.
      # Ensure proper certs and verification if ES is exposed or in strict security environments.
      - ELASTICSEARCH_URL=https://elasticsearch:9200
      - WAZUH_API_URL=https://wazuh-manager:55000
    networks:
      - securiwatch-network
    depends_on:
      elasticsearch:
        condition: service_healthy
      wazuh-manager:
        condition: service_started # No healthcheck available
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '${WZ_DB_CPU_LIMIT:-1}'
          memory: ${WZ_DB_MEM_LIMIT:-1g}
        reservations:
          cpus: '0.25'
          memory: 512m
    # Wazuh dashboard image doesn't have a simple healthcheck endpoint

  # NGINX for secure access to dashboards
  nginx:
    image: nginx:latest
    container_name: nginx
    ports:
      # Changed host ports to avoid conflict with standard 80/443
      - "${HTTP_PORT:-8080}:80"
      - "${HTTPS_PORT:-8443}:443"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/ssl:/etc/nginx/ssl:ro
      - ./config/nginx/.htpasswd:/etc/nginx/.htpasswd:ro
    networks:
      - securiwatch-network
    depends_on:
      wazuh-dashboard:
        condition: service_started # No healthcheck available
      kibana:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '${NGINX_CPU_LIMIT:-0.5}'
          memory: ${NGINX_MEM_LIMIT:-256m}
        reservations:
          cpus: '0.1'
          memory: 128m
    healthcheck:
      # Test config and reachability via loopback on standard ports
      test: ["CMD-SHELL", "nginx -t && curl -sf --resolve localhost:443:127.0.0.1 https://localhost/nginx_health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Alert service for notifications
  alerter:
    build: ./alerter
    container_name: alerter
    volumes:
      - ./alerter/config.yml:/app/config/config.yml:ro
    environment:
      - SMTP_SERVER=${SMTP_SERVER:-}
      - SMTP_PORT=${SMTP_PORT:-587}
      - SMTP_USER=${SMTP_USER:-}
      - SMTP_PASSWORD=${SMTP_PASSWORD:-}
      - ALERT_EMAIL=${ALERT_EMAIL:-}
      - WEBHOOK_URLS=${WEBHOOK_URLS:-}
    networks:
      - securiwatch-network
    depends_on:
      logstash:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '${ALERTER_CPU_LIMIT:-0.25}'
          memory: ${ALERTER_MEM_LIMIT:-128m}
        reservations:
          cpus: '0.05'
          memory: 64m
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # Filebeat to collect logs from host
  filebeat:
    image: docker.elastic.co/beats/filebeat:7.16.2
    container_name: filebeat
    user: root
    volumes:
      - ./config/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      # Mount host logs
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # Use bind mount for data
      - ./data/filebeat:/usr/share/filebeat/data
    networks:
      - securiwatch-network
    depends_on:
      logstash:
        condition: service_healthy
    restart: unless-stopped
    command: filebeat -e -strict.perms=false
    deploy:
      resources:
        limits:
          cpus: '${FB_CPU_LIMIT:-0.5}'
          memory: ${FB_MEM_LIMIT:-256m}
        reservations:
          cpus: '0.1'
          memory: 128m

networks:
  securiwatch-network:
    driver: bridge 